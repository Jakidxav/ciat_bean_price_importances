{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In researching price data for this project, it was became clear that the time frame we could analyze was from 2000-2018 due to the availability of continuous data. We are interested in historical weather variables which we are getting from the [WorldClim](https://www.worldclim.org/data/monthlywth.html) website. These come as `.tif` files, and they are *big*: in total, they are around 100 GB after being unpacked. I cannot host this amount of data on GitHub, so in order to follow along please run this Notebook before any of the others to make sure you have all the geospatial data for the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Data\n",
    "\n",
    "Below, I wrote a method using Python and `wget` that will download zip files from WorldClim, unzip them, and delete all `.tif` files outside of the 2000-2018 time frame. The zip files come in two increments per variable, e.g. we have to download precipitation data from 2000-2009 and then again from 2010-2018. This is a decent amount of data, and downloading 19 years x 12 months = 228 `.tif` files per weather variable we are interested in. The entire process takes ~ 45 minutes (depending on your internet connection, see the printout at the bottom of the method below). I have tried to write the method such that if you already have downloaded the zip files, you should not have to download them again (although this presupposes that the downloads were not interupted, i.e., the files downloaded completely and successfully). In any case, this method checks each directory at the end for the correct number of files, so you will know if you have the complete zip files.\n",
    "\n",
    "There is a small amount of data cleanup at the end to make sure the directories have the right name and to delete uncessary files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so far we are interested in minimimum and maximum temperature, as well as precipitation\n",
    "tmin_url1 = 'biogeo.ucdavis.edu/data/worldclim/v2.1/hist/wc2.1_2.5m_tmin_2000-2009.zip'\n",
    "tmin_url2 = 'biogeo.ucdavis.edu/data/worldclim/v2.1/hist/wc2.1_2.5m_tmin_2010-2018.zip'\n",
    "tmax_url1 = 'biogeo.ucdavis.edu/data/worldclim/v2.1/hist/wc2.1_2.5m_tmax_2000-2009.zip'\n",
    "tmax_url2 = 'biogeo.ucdavis.edu/data/worldclim/v2.1/hist/wc2.1_2.5m_tmax_2010-2018.zip'\n",
    "precip_url1 = 'biogeo.ucdavis.edu/data/worldclim/v2.1/hist/wc2.1_2.5m_prec_2000-2009.zip'\n",
    "precip_url2 = 'biogeo.ucdavis.edu/data/worldclim/v2.1/hist/wc2.1_2.5m_prec_2010-2018.zip'\n",
    "urls = [tmin_url1, tmin_url2, tmax_url1, tmax_url2, precip_url1, precip_url2]\n",
    "\n",
    "#these are the files you should end up with after download\n",
    "tmin_zip1 = 'wc2.1_2.5m_tmin_2000-2009.zip'\n",
    "tmin_zip2 = 'wc2.1_2.5m_tmin_2010-2018.zip'\n",
    "tmax_zip1 = 'wc2.1_2.5m_tmax_2000-2009.zip'\n",
    "tmax_zip2 = 'wc2.1_2.5m_tmax_2010-2018.zip'\n",
    "precip_zip1 = 'wc2.1_2.5m_prec_2000-2009.zip'\n",
    "precip_zip2 = 'wc2.1_2.5m_prec_2010-2018.zip'\n",
    "zip_files = [tmin_zip1, tmin_zip2, tmax_zip1, tmax_zip2, precip_zip1, precip_zip2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jakidxav/ciat_bean_price_feature_importances/data/raw/climate'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../data/raw/climate')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that you are in the right directory! You are running this Notebook in the `notebooks` directory, but should now be in the `raw/climate` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_files_clean_dir(src, dest, new_dir):\n",
    "    \"\"\"\n",
    "    This method copies all files in one directory to another, renames the new directory, \n",
    "    and deletes the source directory.\n",
    "    \n",
    "    Arguments:\n",
    "      src: original directory containing the files you want to copy over\n",
    "      dest: where you want to copy the files\n",
    "      new_dir: what you want to rename `dest`\n",
    "    \"\"\"\n",
    "    for file in os.listdir(src):\n",
    "        shutil.copy(src+file, dest)\n",
    "    os.rename(dest, new_dir)\n",
    "    shutil.rmtree(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_file_if_exists(path_to_file):\n",
    "    \"\"\"\n",
    "    This method \n",
    "    \n",
    "    Args:\n",
    "        path_to_file: this is the path to the filename you want to delete, including the filename\n",
    "    \"\"\"\n",
    "    if os.path.isfile(path_to_file):\n",
    "        os.remove(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_worldclim():\n",
    "    start_time = time.time()\n",
    "    num_files = 228\n",
    "\n",
    "    #download zip files with progress bar\n",
    "    for url in urls:\n",
    "        if os.path.isfile(url[-29:]) == False:\n",
    "            !wget -q {url} --show-progress\n",
    "        else:\n",
    "            print('{} already downloaded.'.format(url[-29:]))\n",
    "\n",
    "    #make sure all files exist\n",
    "    for file in zip_files:\n",
    "        assert(os.path.isfile(file))\n",
    "    print()\n",
    "    \n",
    "    #save the zip file to a directory with the same name (without the .zip extension)\n",
    "    for file in zip_files:\n",
    "        #only make directory if it doesn't exist already\n",
    "        directory = file[:-4]\n",
    "        os.mkdir(directory)\n",
    "        print('Unpacking {}'.format(directory))\n",
    "\n",
    "        #unzip files without producing output\n",
    "        with zipfile.ZipFile(file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(directory)\n",
    "        print('     Done!')\n",
    "    \n",
    "    print()\n",
    "    print('Copying files over, renaming directories, deleting extra files...')\n",
    "    merge_files_clean_dir('./wc2.1_2.5m_tmin_2000-2009/', './wc2.1_2.5m_tmin_2010-2018/', 'wc2.1_2.5m_tmin_2000-2018')\n",
    "    print('Directory ./wc2.1_2.5m_tmin_2000-2018/ created...')\n",
    "    \n",
    "    merge_files_clean_dir('./wc2.1_2.5m_tmax_2000-2009/', './wc2.1_2.5m_tmax_2010-2018/', 'wc2.1_2.5m_tmax_2000-2018')\n",
    "    print('Directory ./wc2.1_2.5m_tmax_2000-2018/ created...')\n",
    "    \n",
    "    merge_files_clean_dir('./wc2.1_2.5m_prec_2000-2009/', './wc2.1_2.5m_prec_2010-2018/', 'wc2.1_2.5m_prec_2000-2018')\n",
    "    print('Directory ./wc2.1_2.5m_prec_2000-2018/ created...')\n",
    "    \n",
    "    #remove extra file for 2019 data\n",
    "    remove_file_if_exists('./wc2.1_2.5m_tmin_2000-2018/wc2.1_2.5m_tmin_2019-12.tif')\n",
    "    remove_file_if_exists('./wc2.1_2.5m_tmax_2000-2018/wc2.1_2.5m_tmax_2019-12.tif')\n",
    "    remove_file_if_exists('./wc2.1_2.5m_prec_2000-2018/wc2.1_2.5m_prec_2019-12.tif')\n",
    "    \n",
    "    #make sure each directory has exactly 228 files\n",
    "    tmin_filenames = sorted(os.listdir('wc2.1_2.5m_tmin_2000-2018'))\n",
    "    tmax_filenames = sorted(os.listdir('wc2.1_2.5m_tmax_2000-2018'))\n",
    "    precip_filenames = sorted(os.listdir('wc2.1_2.5m_prec_2000-2018'))\n",
    "\n",
    "    assert(len(tmin_filenames) == num_files)\n",
    "    assert(len(tmax_filenames) == num_files)\n",
    "    assert(len(precip_filenames) == num_files)\n",
    "    \n",
    "    #remove all zip files\n",
    "    for file in os.listdir():\n",
    "        if file.endswith('.zip'):\n",
    "            os.remove(file)\n",
    "            \n",
    "    remove_file_if_exists('wget-log')\n",
    "        \n",
    "    print('     Done!')\n",
    "\n",
    "    #report time in minutes\n",
    "    end_time = time.time()\n",
    "    total_time = round((end_time - start_time) / 60.0, 2) \n",
    "    print()\n",
    "    print('Total time to download: {} minutes'.format(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc2.1_2.5m_tmin_2000-2009.zip already downloaded.\n",
      "wc2.1_2.5m_tmin_2010-2018.zip already downloaded.\n",
      "wc2.1_2.5m_tmax_2000-2009.zip already downloaded.\n",
      "wc2.1_2.5m_tmax_2010-2018.zip already downloaded.\n",
      "wc2.1_2.5m_prec_2000-2009.zip already downloaded.\n",
      "wc2.1_2.5m_prec_2010-2018.zip already downloaded.\n",
      "\n",
      "Unpacking wc2.1_2.5m_tmin_2000-2009\n",
      "     Done!\n",
      "Unpacking wc2.1_2.5m_tmin_2010-2018\n",
      "     Done!\n",
      "Unpacking wc2.1_2.5m_tmax_2000-2009\n",
      "     Done!\n",
      "Unpacking wc2.1_2.5m_tmax_2010-2018\n",
      "     Done!\n",
      "Unpacking wc2.1_2.5m_prec_2000-2009\n",
      "     Done!\n",
      "Unpacking wc2.1_2.5m_prec_2010-2018\n",
      "     Done!\n",
      "\n",
      "Copying files over, renaming directories, deleting extra files...\n",
      "Directory ./wc2.1_2.5m_tmin_2000-2018/ created...\n",
      "Directory ./wc2.1_2.5m_tmax_2000-2018/ created...\n",
      "Directory ./wc2.1_2.5m_prec_2000-2018/ created...\n",
      "     Done!\n",
      "\n",
      "Total time to download: 12.22 minutes\n"
     ]
    }
   ],
   "source": [
    "download_worldclim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
